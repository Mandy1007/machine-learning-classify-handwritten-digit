{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import gzip\n",
    "import numpy as np\n",
    "import cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class costQuadratic(object):\n",
    "    @staticmethod\n",
    "    #y is the real value, a is the estimate value from neural network\n",
    "    def realCost(a,y):\n",
    "        return 0.5*np.linalg.norm(a-y)**2\n",
    "    @staticmethod\n",
    "    def delta(z,a,y):\n",
    "        #z is the putput from the previous layer\n",
    "        return (a-y)*dif_sigmoid(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class costCrossEntropy(object):\n",
    "    @staticmethod\n",
    "    def realCost(a,y):\n",
    "        return np.sum(np.nan_to_sum(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "    @staticmethod\n",
    "    def delta(z,a,y):\n",
    "        return (a-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f=gzip.open('../mnist.pkl.gz', 'rb')\n",
    "    training_data,validation_data,test_data= cPickle.load(f)\n",
    "    f.close()\n",
    "    return (training_data,validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make the result into a evector\n",
    "def vectorized_result(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    training_data = zip(training_inputs, training_results)\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = zip(validation_inputs, va_d[1])\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_data = zip(test_inputs, te_d[1])\n",
    "    return (training_data, validation_data, test_data) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data,test_data=load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self,sizes,cost=costCrossEntropy):\n",
    "        #sizes is something like [784,20,10], so the first \n",
    "        #layer has 784 nodes, second layer has 20 layers\n",
    "        #and output is 10 layers\n",
    "        self.num_layers=len(sizes)\n",
    "        self.sizes=sizes\n",
    "        self.default_weight_initializer()\n",
    "        #the above function will initialize the weight differently\n",
    "        self.cost=cost\n",
    "    def default_weight_initializer(self):\n",
    "        self.biases=[np.random.randn(y,1) for y in self.sizes[1:]]\n",
    "        \n",
    "        \n",
    "        self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "    def large_weight_initializer(self):\n",
    "        self.biases=[np.random.randn(y,1) for y in self.sizes[1:]]\n",
    "        self.weights=[np.random.randn(y, x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "    def feedforward(self,a):\n",
    "        #a is from the input layer,\n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            a=sigmoid(np.dot(w,a)+b)\n",
    "        #after this loop,a is the output layer\n",
    "        return a\n",
    "    def SGD(self, training_data,epoches,mini_batch_size,ita,lamda=0.0,\n",
    "           evaluation_data=None,monitor_evaluation_cost=False,\n",
    "           monitor_evaluation_accuracy=False,monitor_training_cost=False,\n",
    "           monitor_training_accuracy=False):\n",
    "        #mini-batch size is the mini size for stochatic gradient descent\n",
    "        if evaluation_data:n_data=len(evaluation_data)\n",
    "        else:n_data=0\n",
    "        n=len(training_data)\n",
    "        training_cost, training_accuracy=[],[]\n",
    "        evaluation_cost,evaluation_accuracy=[],[]\n",
    "        for k in xrange(epoches):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batch_array=[training_data[i:i+mini_batch_size]\n",
    "                             for i in xrange(0,n,mini_batch_size)]\n",
    "            for mini_batch in mini_batch_array:\n",
    "                self.update_mini_parameters(mini_batch,ita,lamda,n_data)\n",
    "            print \"Epoch %s training finished\" %k\n",
    "            if monitor_training_cost:\n",
    "                cost=self.total_cost(training_data,lamda)\n",
    "                training_cost.append(cost)\n",
    "            if monitor_training_accuracy:\n",
    "                accuracy=self.accuracy(training_data,convert=True)\n",
    "                training_accuracy.append(accuracy)\n",
    "            if monitor_evaluation_cost:\n",
    "                cost=self.total_cost(evalucation_data,lamda,convert=True)\n",
    "                evaluation_cost.append(cost)\n",
    "            if monitor_evaluation_accuracy:\n",
    "                accuracy=self.accuracy(evaluation_data)\n",
    "                evaluation_accuracy.append(accuracy)\n",
    "                print \"Accuracy on evaluation data: {} / {}\".format(\n",
    "                    self.accuracy(evaluation_data), n_data)\n",
    "            print\n",
    "        return evaluation_cost,evaluation_accuracy,training_cost,training_accuracy\n",
    "    def update_mini_parameters(self,mini_batch,ita,lamda,wholeRecordCount):\n",
    "        pre_update_b=[np.zeros(b.shape) for b in self.biases]\n",
    "        #this is the way to create the same shape of matrix of biases and weight\n",
    "        pre_update_w=[np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x,y in mini_batch:\n",
    "            delta_pre_update_b,delta_pre_update_w=self.backProp(x,y)\n",
    "            pre_update_b=[b+db for b,db in zip(pre_update_b,delta_pre_update_b)]\n",
    "            pre_update_w=[w+dw for w,dw in zip(pre_update_w,delta_pre_update_w)]\n",
    "        self.weights=[(1-ita*(lamda/wholeRecordCount))*w-(ita/len(mini_batch))*deltaW \n",
    "                       for w,deltaW in zip(self.weights,pre_update_w)]\n",
    "        #here divide by len(min_batch) is to average the delta over the minibactch\n",
    "        #then we do update weights and biases later\n",
    "        #we don't do regularization for b, according to the reason in the book\n",
    "        self.biases=[b-(ita/len(mini_batch))*deltaB \n",
    "                    for b, deltaB in zip(self.biases,pre_update_b)]\n",
    "    \n",
    "    def backProp(self,x,y):\n",
    "        #return the gradient of weights and biases for cost function\n",
    "        #this is just for one record, so in order to do derivative\n",
    "        #on the average cost function then get the gradient, is\n",
    "        #equivalent to do the gradient calculation one by one and then take the\n",
    "        #average between the gradient,which will be done in update_mini_parameters\n",
    "        pre_update_b=[np.zeros(b.shape) for b in self.biases]\n",
    "        pre_update_w=[np.zeros(w.shape) for w in self.weights]\n",
    "        #feedforward now\n",
    "        activation=x\n",
    "        activations=[x] \n",
    "        #this is a matrix to store all the act\n",
    "        #ivations, layer by layer\n",
    "        sumActions=[] \n",
    "        #matrix to store all the sum whcih is before we take the sigmoid function\n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            sumAction=np.dot(w,activation)+b\n",
    "            sumActions.append(sumAction)\n",
    "            activation=sigmoid(sumAction)\n",
    "            activations.append(activation)\n",
    "        #backward\n",
    "        #the following structure set up in order for us to use \n",
    "        #different cost function,say quadratic cost function delta need to \n",
    "        #multiply the sigmoid_prime and crossEntropy don't need to do that\n",
    "        delta_depend_costFunction=(self.cost).delta(sumActions[-1],activations[-1],y)\n",
    "        pre_update_b[-1]=delta_depend_costFunction\n",
    "        pre_update_w[-1]=np.dot(delta_depend_costFunction,activations[-2].transpose())\n",
    "        #testing the feature of np.dot like this, so say I have 784,5,10 sizes\n",
    "        #layerso now delta is 10*1 and activations[-2].transpose is 1*5 so we \n",
    "        #get a 10*5 matrix after the dot and delta for each node in the hidden layer will\n",
    "        #be on the column of this matrix\n",
    "        #the above is about the last layer so it is the initialization of delta\n",
    "        #now we need to calculate delta for other layers\n",
    "        for l in xrange(2,self.num_layers):\n",
    "            sumAction=sumActions[-l]\n",
    "            sp=diff_sigmoid(sumAction)\n",
    "            #here weights.transpose shape is (5,10) and delta is (10,5),sp is (5,1),so we will get a (5,1)\n",
    "            #this is the delta for the hidden layer example\n",
    "            delta_depend_costFunction=np.dot(self.weights[-l+1].transpose(),delta_depend_costFunction)*sp\n",
    "            pre_update_b[-l]=delta_depend_costFunction\n",
    "            #delta is (5,1) and activations[-l-1] is (10,1), so we need a transpose,so delta_weight is (5,10),\n",
    "            #the same as our weight matrix setup.(which the weight set up is the inverse of the formula set up)\n",
    "            pre_update_w[-l]=np.dot(delta_depend_costFunction,activations[-l-1].transpose())\n",
    "            #so the idea is the sigmoid_prime is from the current layer, x(i) is from the previous layer (-l-1) and\n",
    "            #the w(jk) is from the later layer, look at the formula from Dr.Amy\n",
    "        #pre_update_b has the same shape with biases\n",
    "        #pre_update_w has the same shape with weights\n",
    "        return (pre_update_b,pre_update_w)\n",
    "       \n",
    "    def accuracy(self,data,convert=False):\n",
    "        #return the number of record the network predict correct\n",
    "        #convert is False means this accuracy is for test or validation data\n",
    "        #since the usual case is to see the accuracy on test data\n",
    "        #teh set up for traning data is different from the set of testing data\n",
    "        #since we need to do matrix multiplication on the output vector \n",
    "        #in the training data\n",
    "\n",
    "        if convert:\n",
    "            results=[(np.argmax(self.feedforward(x)),np.argmax(y)) for (x,y) in data]\n",
    "        else:\n",
    "            results=[(np.argmax(self.feedforward(x)),y) for (x,y) in data]\n",
    "        \n",
    "        return sum(int(x==y) for (x,y) in results)\n",
    "    def total_cost(self,data,lamda,convert=False):\n",
    "        #the default total cost is on the validation data\n",
    "        #and this is the cost oevr all the data,not the stochastic gradient one\n",
    "        cost=0.0\n",
    "        for x,y in data:\n",
    "            estimated=self.feedforward(x)\n",
    "            if convert: y=vectorized_result(y)\n",
    "            cost=cost+self.cost.realCost/len(data)\n",
    "        #the following is to add in the regularization part\n",
    "        cost=cost+0.5*(lamda/len(data))*sum(np.linalg.norm(w)**2 for w in self.weights)\n",
    "        #so the above sum part is a good way to sum up all the element in a matrix\n",
    "        return cost\n",
    "    \n",
    "    #save the training result to a file\n",
    "    def save(self,filename):\n",
    "        #put the data in the dictionary\n",
    "        data={\n",
    "            \"sizes\":self.sizes,\n",
    "            \"weights\":[w.tolist() for w in self.weights],\n",
    "            \"biases\":[b.tolist() for b in self.biases],\n",
    "            \"cost\":str(self.cost.__name__)\n",
    "            #above is kind of reflection to get the costFunctionName\n",
    "        }\n",
    "        f=open(filename,\"w\")\n",
    "        json.dump(data,f)\n",
    "        f.close()\n",
    "    #the following is load in an already trained network\n",
    "    def load(filename):\n",
    "        #return an instance of the network\n",
    "        f=open(filename,\"r\")\n",
    "        data=json.load(f)\n",
    "        f.close()\n",
    "        cost=getattr(sys.modules[__name__],data[\"cost\"])\n",
    "        #load in the cost function for the network\n",
    "        net=Network(data[\"sizes\"],cost=cost)\n",
    "        net.weights=[np.array(w) for w in data[\"weights\"]]\n",
    "        net.biases=[np.array(b) for b in data[\"biases\"]]\n",
    "        return net\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=np.reshape(data_test[0][0][0],(784,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=data_test[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Network([784, 5, 10], cost=costCrossEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 784)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=net.backProp(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.23556702],\n",
       "       [-4.25745572],\n",
       "       [-4.0979444 ],\n",
       "       [-4.26282567],\n",
       "       [-4.75326355],\n",
       "       [-4.46624455],\n",
       "       [-4.69541625],\n",
       "       [-4.17206748],\n",
       "       [-4.86077479],\n",
       "       [-4.60826392]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27473737],\n",
       "       [ 0.57892272],\n",
       "       [ 0.59674144],\n",
       "       [ 0.71654454],\n",
       "       [ 0.29883683]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdot=np.dot(test[0],test[1].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.16366853, -2.45206598, -2.52753838, -3.03497241, -1.26574341],\n",
       "       [-1.16968218, -2.46473784, -2.54060027, -3.05065663, -1.27228456],\n",
       "       [-1.12585846, -2.37239312, -2.44541326, -2.93635967, -1.2246167 ],\n",
       "       [-1.1711575 , -2.46784663, -2.54380474, -3.05450445, -1.2738893 ],\n",
       "       [-1.30589912, -2.75177226, -2.83646935, -3.40592503, -1.4204502 ],\n",
       "       [-1.22704427, -2.58561044, -2.66519322, -3.20026313, -1.33467835],\n",
       "       [-1.2900063 , -2.71828314, -2.80194947, -3.36447486, -1.40316329],\n",
       "       [-1.14622284, -2.41530465, -2.48964557, -2.98947216, -1.24676741],\n",
       "       [-1.33543647, -2.81401296, -2.90062576, -3.48296162, -1.45257852],\n",
       "       [-1.2660623 , -2.66782868, -2.74994206, -3.30202634, -1.37711897]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdot=np.dot(test[1],test[0].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.16366853, -1.16968218, -1.12585846, -1.1711575 , -1.30589912,\n",
       "        -1.22704427, -1.2900063 , -1.14622284, -1.33543647, -1.2660623 ],\n",
       "       [-2.45206598, -2.46473784, -2.37239312, -2.46784663, -2.75177226,\n",
       "        -2.58561044, -2.71828314, -2.41530465, -2.81401296, -2.66782868],\n",
       "       [-2.52753838, -2.54060027, -2.44541326, -2.54380474, -2.83646935,\n",
       "        -2.66519322, -2.80194947, -2.48964557, -2.90062576, -2.74994206],\n",
       "       [-3.03497241, -3.05065663, -2.93635967, -3.05450445, -3.40592503,\n",
       "        -3.20026313, -3.36447486, -2.98947216, -3.48296162, -3.30202634],\n",
       "       [-1.26574341, -1.27228456, -1.2246167 , -1.2738893 , -1.4204502 ,\n",
       "        -1.33467835, -1.40316329, -1.24676741, -1.45257852, -1.37711897]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8420 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 8836 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 8980 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9067 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9111 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9119 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9197 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9217 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9242 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9209 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9252 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9260 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9248 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9229 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9282 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9259 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9258 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9285 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9261 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9260 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9283 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9295 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9292 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9266 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9299 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9283 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9273 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9252 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9267 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9249 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 10, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "oneHidden10=net.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 9087 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9292 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9458 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9533 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9569 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9587 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9608 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9603 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9623 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9640 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9677 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9673 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9665 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9681 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9651 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9682 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9682 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9677 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9698 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9685 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9697 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9700 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9709 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9704 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 100, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "oneHidden100=net.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 9110 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9363 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9500 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9554 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9570 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9610 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9605 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9654 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9637 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9661 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9667 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9649 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9681 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9645 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9680 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9680 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9693 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9697 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9704 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9675 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9682 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9712 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9690 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9692 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 200, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "oneHidden200=net.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8621 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9090 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9218 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9343 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9374 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9402 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9490 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9497 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9535 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9491 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9504 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9489 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9550 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9534 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9543 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9552 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9548 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9585 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9568 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9550 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9557 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9545 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9560 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9526 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9556 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9562 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9540 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9561 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 20,20, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "twoHidden2020=net.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8792 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9121 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9363 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9493 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9554 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9571 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9632 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9619 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9586 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9650 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9664 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9649 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9684 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9657 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9673 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9687 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9665 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9693 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9692 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9691 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9688 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9691 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9695 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9714 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9686 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9705 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9704 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9695 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 50,20, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "twoHidden5020=net.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8515 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 8887 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9089 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9171 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9229 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9263 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9310 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9332 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9357 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9394 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9392 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9383 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9416 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9400 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9413 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9447 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9449 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9447 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9478 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9475 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9477 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9479 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9489 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no regularization case:\n",
    "net = Network([784, 50,20, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "twoHidden5020_noReg=net.SGD(training_data, 30, 10, 0.1, lamda = 0.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  2.72626027e-04,   4.16905976e-06,  -1.02379946e-03, ...,\n",
      "         -2.69032803e-04,   1.21669158e-04,   1.36562026e-03],\n",
      "       [  1.15387630e-04,  -2.95285917e-05,  -1.44881540e-05, ...,\n",
      "          1.15017348e-04,  -1.79013199e-04,  -8.09636463e-04],\n",
      "       [ -3.09749864e-04,  -2.17425376e-05,  -9.27882443e-04, ...,\n",
      "         -8.66207998e-05,  -5.97753853e-04,  -2.20254944e-04],\n",
      "       ..., \n",
      "       [ -1.38442536e-04,   1.14865962e-03,  -1.76211855e-04, ...,\n",
      "          5.02335012e-04,  -5.99548268e-04,  -3.13493347e-04],\n",
      "       [ -7.86918172e-04,  -4.39724781e-04,   5.72829654e-04, ...,\n",
      "         -1.66786869e-03,   3.63998348e-04,  -2.27458083e-06],\n",
      "       [  2.36763553e-04,  -4.93328791e-04,  -3.40238454e-05, ...,\n",
      "          3.88059737e-04,  -6.02968839e-04,  -8.03264401e-04]]), array([[-2.97531407, -1.65439102,  1.17551978, -2.16417665, -0.36744316,\n",
      "         4.16211897, -2.43242933,  2.11827459, -1.5647029 , -3.72870387],\n",
      "       [ 2.42087534, -1.35000517, -2.10363627, -0.39025526,  5.42009852,\n",
      "        -1.73265225, -0.92122894,  0.90143011, -1.79359397,  1.62060037],\n",
      "       [ 3.37169632, -0.28850328,  1.72643947, -1.65753926, -2.0998376 ,\n",
      "        -2.72135973,  2.95706017,  1.59295542, -0.93240274, -3.72052916],\n",
      "       [ 4.10008907,  0.16675133,  0.88192276, -3.10396242, -2.76481032,\n",
      "         1.54553091, -1.48595997, -3.3948612 , -1.62250288,  2.33924985],\n",
      "       [-1.01048308,  4.37478804,  2.92818754, -1.97274778, -0.4009502 ,\n",
      "        -2.16185221, -1.30183223,  0.41589665,  4.16411759,  0.40962403],\n",
      "       [-2.79219457, -0.04555543,  2.83187434,  4.78149818,  3.28185526,\n",
      "         1.40649862,  2.34378653, -2.57557578, -0.82610465,  1.33408701],\n",
      "       [-1.29343479,  3.49632721, -2.87955064,  3.08009368, -0.51963845,\n",
      "        -1.5820547 , -1.16194855,  1.81630724, -2.83654401, -2.2265114 ],\n",
      "       [ 1.17078362,  0.32767228, -2.64263669, -0.76249501, -1.2114484 ,\n",
      "         3.27533864,  3.34998144,  2.09439889,  3.2113308 ,  1.81138132],\n",
      "       [-3.39585893, -1.8002699 ,  1.59970476, -2.31983834, -2.42335231,\n",
      "        -3.42177696, -0.52858384,  2.67813754, -4.87588007,  4.03551291],\n",
      "       [-2.72401443, -4.30323098, -2.19620873, -0.50113036, -0.28259189,\n",
      "        -2.69746202, -3.41005559, -1.99696374,  4.1992972 , -0.17208596]])]\n"
     ]
    }
   ],
   "source": [
    "print net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.32876478],\n",
      "       [ 0.36094367],\n",
      "       [ 0.06721656],\n",
      "       [-0.48018359],\n",
      "       [ 0.65424671],\n",
      "       [ 0.95461411],\n",
      "       [-0.04264859],\n",
      "       [ 0.95929357],\n",
      "       [ 1.0122879 ],\n",
      "       [ 0.1860195 ]]), array([[-3.68648201],\n",
      "       [-5.35651112],\n",
      "       [-4.71432446],\n",
      "       [-4.11723353],\n",
      "       [-8.30516597],\n",
      "       [-6.25661023],\n",
      "       [-2.76937582],\n",
      "       [-9.36402472],\n",
      "       [-4.67591271],\n",
      "       [ 0.79349309]])]\n"
     ]
    }
   ],
   "source": [
    "print net.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def svm_baseline():\n",
    "    training_data, validation_data, test_data = load_data()\n",
    "# train\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(training_data[0], training_data[1])\n",
    "# test\n",
    "    predictions = [int(a) for a in clf.predict(test_data[0])]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1]))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def giveMeThePercentage(arrayToChange):\n",
    "    return [round(x/10000.0,3) for x in arrayToChange]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oneHidden10Per=giveMeThePercentage(oneHidden10[1])\n",
    "oneHidden100Per=giveMeThePercentage(oneHidden100[1])\n",
    "oneHidden200Per=giveMeThePercentage(oneHidden200[1])\n",
    "twoHidden2020Per=giveMeThePercentage(twoHidden2020[1])\n",
    "twoHidden5020Per=giveMeThePercentage(twoHidden5020[1])\n",
    "twoHidden5020Per_noReg=giveMeThePercentage(twoHidden5020_noReg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(oneHidden10Per,'r',label=\"1 hidden 10\")\n",
    "plt.plot(oneHidden100Per,'g',label=\"1 hidden 100\")\n",
    "plt.plot(oneHidden200Per,'b',label=\"1 hidden 200\")\n",
    "plt.plot(twoHidden2020Per,'y',label=\"2 hidden 20 20\")\n",
    "plt.plot(twoHidden5020Per,'k',marker=\"o\",label=\"2 hidden 50 20\")\n",
    "plt.plot(twoHidden5020Per_noReg,'k',marker=\"*\",label=\"2 hidden 50 20 no reg\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def svm_baseline():\n",
    "    training_data, validation_data, test_data = load_data()\n",
    "# train\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(training_data[0], training_data[1])\n",
    "# test\n",
    "    predictions = [int(a) for a in clf.predict(test_data[0])]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1]))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "9435 of 10000 values correct.\n",
      "CPU times: user 10min, sys: 1.72 s, total: 10min 2s\n",
      "Wall time: 10min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "svm_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 9065 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9325 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9425 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9517 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9580 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9598 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9650 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9667 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9650 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9655 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9670 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9684 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9669 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9697 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9645 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9689 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9668 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9676 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9643 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9692 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9678 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9688 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9688 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9683 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9680 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 100, 10], cost=costCrossEntropy)\n",
    "net.large_weight_initializer()\n",
    "oneHidden10=net.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights=net.weights\n",
    "biases=net.biases\n",
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newWeights=net1.weights\n",
    "newBiases=net1.biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSigmoidForArray(array):\n",
    "    return [sigmoid(x) for x in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newTest=[getSigmoidForArray(x) for x in newTrainingData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstLayerResult=[sigmoid(x)for x in ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden(100,weights,biases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden(n_neurons,weights,biases):\n",
    "    newTrainingData=[]\n",
    "    for j in xrange(0,50000):\n",
    "        tempArray=np.zeros((n_neurons,))\n",
    "        for i in xrange(0,n_neurons):\n",
    "            tempArray[i]=np.dot(training_data[0][j].transpose(),weights[0][i])+biases[0][i]\n",
    "        newTrainingData.append(tempArray)\n",
    "    return newTrainingData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataOneHidden(n_neurons,weights,biases):\n",
    "    newTrainingData=[]\n",
    "    for j in xrange(0,10000):\n",
    "        tempArray=np.zeros((n_neurons,))\n",
    "        for i in xrange(0,n_neurons):\n",
    "            tempArray[i]=np.dot(test_data[0][j].transpose(),weights[0][i])+biases[0][i]\n",
    "        newTrainingData.append(tempArray)\n",
    "    return newTrainingData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTwoHidden(n_neurons1,n_neurons2,weights,biases):\n",
    "    firstLayerResult=[sigmoid(x) for x in ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden(n_neurons1,weights,biases)]\n",
    "    newTrainingData=[]\n",
    "    for j in xrange(0,50000):\n",
    "        tempArray=np.zeros((n_neurons2,))\n",
    "        for i in xrange(0,n_neurons2):\n",
    "            tempArray[i]=np.dot(firstLayerResult[j].transpose(),weights[1][i])+biases[1][i]\n",
    "        newTrainingData.append(tempArray)\n",
    "    return newTrainingData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataTwoHidden(n_neurons1,n_neurons2,weights,biases):\n",
    "    firstLayerResult=[sigmoid(x) for x in ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataOneHidden(n_neurons1,weights,biases)]\n",
    "    newTrainingData=[]\n",
    "    for j in xrange(0,10000):\n",
    "        tempArray=np.zeros((n_neurons2,))\n",
    "        for i in xrange(0,n_neurons2):\n",
    "            tempArray[i]=np.dot(firstLayerResult[j].transpose(),weights[1][i])+biases[1][i]\n",
    "        newTrainingData.append(tempArray)\n",
    "    return newTrainingData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-91dbd4f378ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewTrainingData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnewTestData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataOneHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "newTrainingData=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden(100,weights,biases)\n",
    "newTestData=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataOneHidden(100,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newTrainingDataTwoLayers=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTwoHidden(50,20,newWeights,newBiases)\n",
    "newTestDataTwoLayers=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataTwoHidden(50,20,newWeights,newBiases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def svm_nn_combine():\n",
    "    training_data, validation_data, test_data = load_data()\n",
    "# train\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(newTrainingData, training_data[1])\n",
    "# test\n",
    "    predictions = [int(a) for a in clf.predict(newTestData)]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1]))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def svm_nn_combine_2layers():\n",
    "    training_data, validation_data, test_data = load_data()\n",
    "# train\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(newTrainingDataTwoLayers, training_data[1])\n",
    "# test\n",
    "    predictions = [int(a) for a in clf.predict(newTestDataTwoLayers)]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1]))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def svm_nn_combine_2layers_sigmoid_kernel():\n",
    "    training_data, validation_data, test_data = load_data()\n",
    "# train\n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    clf.fit(newTrainingDataTwoLayers, training_data[1])\n",
    "# test\n",
    "    predictions = [int(a) for a in clf.predict(newTestDataTwoLayers)]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1]))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(test_data[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "9757 of 10000 values correct.\n",
      "CPU times: user 4min 52s, sys: 1.29 s, total: 4min 53s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare to the pure nn which is 9680, so it does enhance it when add in svm but for 10 neurons in first hidden layer,\n",
    "it decrease the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "7624 of 10000 values correct.\n",
      "CPU times: user 10min 9s, sys: 3.3 s, total: 10min 12s\n",
      "Wall time: 10min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine_2layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not enhance the performance at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data,test_data=load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 9183 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9403 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9505 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9523 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9647 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9654 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9655 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9670 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9651 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9675 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9653 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9692 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9691 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9690 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9709 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9685 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9699 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9686 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9698 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9700 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9685 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9698 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9681 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9701 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9701 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9710 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9716 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net200 = Network([784,200,10], cost=costCrossEntropy)\n",
    "net200.large_weight_initializer()\n",
    "twoHidden5020=net200.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights200=net200.weights\n",
    "biases200=net200.biases\n",
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newTrainingData=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden(200,weights200,biases200)\n",
    "newTestData=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataOneHidden(200,weights200,biases200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "9798 of 10000 values correct.\n",
      "CPU times: user 3min 34s, sys: 614 ms, total: 3min 34s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compare to 9716 with 9798 so get enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data,test_data=load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8761 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9139 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9322 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9475 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9537 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9638 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9662 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9618 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9653 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9658 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9668 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9660 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9661 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9689 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9668 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9688 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9677 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9688 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9689 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9678 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9692 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9699 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9699 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net5020 = Network([784, 50,20, 10], cost=costCrossEntropy)\n",
    "net5020.large_weight_initializer()\n",
    "twoHidden5020=net5020.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights5020=net5020.weights\n",
    "biases5020=net5020.biases\n",
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newTrainingDataTwoLayers=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTwoHidden(50,20,weights5020,biases5020)\n",
    "newTestDataTwoLayers=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataTwoHidden(50,20,weights5020,biases5020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "9756 of 10000 values correct.\n",
      "CPU times: user 16.7 s, sys: 80.5 ms, total: 16.8 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine_2layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is obvious faster than the 97.56 than 97.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8591 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 9081 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9227 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9328 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9363 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9449 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9446 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9478 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9527 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9538 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9547 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9529 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9541 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9535 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9521 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9553 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9551 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9547 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9564 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9563 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9588 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9584 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9486 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9590 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9584 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9552 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9585 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9568 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9595 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net2020 = Network([784, 20,20, 10], cost=costCrossEntropy)\n",
    "net2020.large_weight_initializer()\n",
    "oneHidden10=net2020.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights2020=net2020.weights\n",
    "biases2020=net2020.biases\n",
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newTrainingDataTwoLayers=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTwoHidden(20,20,weights2020,biases2020)\n",
    "newTestDataTwoLayers=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataTwoHidden(20,20,weights2020,biases2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "9625 of 10000 values correct.\n",
      "CPU times: user 18.8 s, sys: 103 ms, total: 18.9 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine_2layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "1135 of 10000 values correct.\n",
      "CPU times: user 4min 21s, sys: 2.92 s, total: 4min 24s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine_2layers_sigmoid_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#obviously sigmoid kernel for svm is not good for this problem,\n",
    "#the default kernel is 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training finished\n",
      "Accuracy on evaluation data: 8376 / 10000\n",
      "\n",
      "Epoch 1 training finished\n",
      "Accuracy on evaluation data: 8806 / 10000\n",
      "\n",
      "Epoch 2 training finished\n",
      "Accuracy on evaluation data: 9043 / 10000\n",
      "\n",
      "Epoch 3 training finished\n",
      "Accuracy on evaluation data: 9128 / 10000\n",
      "\n",
      "Epoch 4 training finished\n",
      "Accuracy on evaluation data: 9193 / 10000\n",
      "\n",
      "Epoch 5 training finished\n",
      "Accuracy on evaluation data: 9179 / 10000\n",
      "\n",
      "Epoch 6 training finished\n",
      "Accuracy on evaluation data: 9209 / 10000\n",
      "\n",
      "Epoch 7 training finished\n",
      "Accuracy on evaluation data: 9280 / 10000\n",
      "\n",
      "Epoch 8 training finished\n",
      "Accuracy on evaluation data: 9262 / 10000\n",
      "\n",
      "Epoch 9 training finished\n",
      "Accuracy on evaluation data: 9246 / 10000\n",
      "\n",
      "Epoch 10 training finished\n",
      "Accuracy on evaluation data: 9287 / 10000\n",
      "\n",
      "Epoch 11 training finished\n",
      "Accuracy on evaluation data: 9297 / 10000\n",
      "\n",
      "Epoch 12 training finished\n",
      "Accuracy on evaluation data: 9275 / 10000\n",
      "\n",
      "Epoch 13 training finished\n",
      "Accuracy on evaluation data: 9262 / 10000\n",
      "\n",
      "Epoch 14 training finished\n",
      "Accuracy on evaluation data: 9262 / 10000\n",
      "\n",
      "Epoch 15 training finished\n",
      "Accuracy on evaluation data: 9269 / 10000\n",
      "\n",
      "Epoch 16 training finished\n",
      "Accuracy on evaluation data: 9273 / 10000\n",
      "\n",
      "Epoch 17 training finished\n",
      "Accuracy on evaluation data: 9282 / 10000\n",
      "\n",
      "Epoch 18 training finished\n",
      "Accuracy on evaluation data: 9249 / 10000\n",
      "\n",
      "Epoch 19 training finished\n",
      "Accuracy on evaluation data: 9248 / 10000\n",
      "\n",
      "Epoch 20 training finished\n",
      "Accuracy on evaluation data: 9282 / 10000\n",
      "\n",
      "Epoch 21 training finished\n",
      "Accuracy on evaluation data: 9307 / 10000\n",
      "\n",
      "Epoch 22 training finished\n",
      "Accuracy on evaluation data: 9289 / 10000\n",
      "\n",
      "Epoch 23 training finished\n",
      "Accuracy on evaluation data: 9265 / 10000\n",
      "\n",
      "Epoch 24 training finished\n",
      "Accuracy on evaluation data: 9263 / 10000\n",
      "\n",
      "Epoch 25 training finished\n",
      "Accuracy on evaluation data: 9285 / 10000\n",
      "\n",
      "Epoch 26 training finished\n",
      "Accuracy on evaluation data: 9277 / 10000\n",
      "\n",
      "Epoch 27 training finished\n",
      "Accuracy on evaluation data: 9273 / 10000\n",
      "\n",
      "Epoch 28 training finished\n",
      "Accuracy on evaluation data: 9256 / 10000\n",
      "\n",
      "Epoch 29 training finished\n",
      "Accuracy on evaluation data: 9297 / 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data, validation_data,test_data=load_data_wrapper()\n",
    "net10 = Network([784, 10, 10], cost=costCrossEntropy)\n",
    "net10.large_weight_initializer()\n",
    "oneHidden10=net10.SGD(training_data, 30, 10, 0.1, lamda = 5.0,\n",
    "        evaluation_data=validation_data, \n",
    "        monitor_evaluation_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights10=net10.weights\n",
    "biases10=net10.biases\n",
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newTrainingData=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionOneHidden(10,weights10,biases10)\n",
    "newTestData=ToGetTheLastHiddenLayerValueBeforeGoToSigmoidFunctionTestDataOneHidden(10,weights10,biases10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classifier using an SVM.\n",
      "8523 of 10000 values correct.\n",
      "CPU times: user 7min 10s, sys: 3.46 s, total: 7min 14s\n",
      "Wall time: 7min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_nn_combine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
